### 20250619
[OpenAI Evals design best practices](https://platform.openai.com/docs/guides/evals-design)  
一句话总结：  
介绍了Eval的概念、必要性和方法。

概念：  
> Evals are structured tests for measuring a model's performance.   

是模型表现的结构化测试

必要性：  
> one of the only ways to improve performance of an LLM-based application

为数不多的，可以优化LLM应用的方法

工作流程：  
1. 确定评测目标
2. 收集数据集
3. 定义评测指标
4. 评测、迭代
5. 持续评测、迭代

关键点：
* 识别出由用户、模型引入的不确定性
    * 找出评测不确定性的关键方向
    * 列出具体的评测问题
---
[Evals design best practices
](https://platform.openai.com/docs/guides/evals-design#create-and-combine-different-types-of-evaluators)  
介绍了对文本总结结果评测的三种方法，并给出了示例：
- [ROUGE](https://aclanthology.org/W04-1013/)
- [BERTScore](https://arxiv.org/abs/1904.09675)
- [G-EVAL](https://arxiv.org/pdf/2303.16634.pdf)

其中G-EVAL的过程比较详细，给出了详细的prompt和代码

> 我问了claude4一个引申问题:  
如果我需要对中文内容，的summary结果做评测，那么prompt是否需要使用中文写？  
回答：  
使用中文prompt
主要原因：
语言一致性：当评测中文内容时，使用中文prompt能确保评测标准更符合中文语言特点
文化适应性：中文的表达习惯、语法结构与英文不同，中文prompt能更好地体现这些差异
评测精度：模型在相同语言环境下的评测往往更准确

---
TOREAD:   
[How to evaluate a summarization task](https://cookbook.openai.com/examples/evaluation/how_to_eval_abstractive_summarization)

[Evaluating model performance](https://platform.openai.com/docs/guides/evals)

[github.com/openai/codex](https://github.com/openai/codex)

 